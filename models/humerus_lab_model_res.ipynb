{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337c0af3",
   "metadata": {},
   "source": [
    "# 3D CAE Model Humerus Labelmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb87400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import h5py\n",
    "from skimage.transform import downscale_local_mean,resize\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score,calinski_harabasz_score,davies_bouldin_score\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv3D,Conv3DTranspose,Dense,MaxPooling3D,UpSampling3D,Flatten,Dense,Reshape,GlobalAveragePooling3D,BatchNormalization,Dropout\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from itkwidgets import view\n",
    "\n",
    "# My imports (se si modifica il file bisogna riavviare tutto il kernel)\n",
    "from utilities import plot_all_slices_notzero,plot_slices,dice_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec2b16-681e-4e71-98b9-c2563894c713",
   "metadata": {
    "tags": []
   },
   "source": [
    "st=time.time()\n",
    "with h5py.File(\"dataset_humerus_labelmap_res.hdf5\",\"r\") as f:\n",
    "    humerus_dataset = f.get(\"mydataset\")[:]\n",
    "print(f\"Tempo lettura dataset: {time.time()-st:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12724283-145f-4529-9e49-44d7198b54ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st=time.time()\n",
    "with h5py.File(\"dataset_humerus_labelmap_res_flipped.hdf5\",\"r\") as f:\n",
    "    humerus_dataset = f.get(\"mydataset\")[:]\n",
    "print(f\"Tempo lettura dataset: {time.time()-st:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76801a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "humerus_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4f755",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Downsampling\n",
    "\n",
    "Meglio inziare con un downsampling per evitare problemi di memoria inizialmente.\n",
    "\n",
    "Dataset: 288x210x393\\\n",
    "Padding a: 288x216x400\\\n",
    "Downsample per 4 a: 72x54x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f47a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "humerus_dataset = np.pad(humerus_dataset,((0,0),(0,0),(3,3),(4,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef21f5-5284-48c4-84c9-5c20396609cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "humerus_dataset = resize(humerus_dataset,(humerus_dataset.shape[0],humerus_dataset.shape[1]/4,humerus_dataset.shape[2]/4,humerus_dataset.shape[3]/4),preserve_range=True,order=0,anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d200a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "humerus_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c03c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"resized_dataset_humerus_labelmap_res_flipped.hdf5\",\"w\") as f:\n",
    "    f.create_dataset(\"mydataset\",data=humerus_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3d15c",
   "metadata": {},
   "source": [
    "# Model downsampled\n",
    "\n",
    "Una volta importato il dataset possiamo iniziare ad occuparci della costruzione del modello. Partiamo da immagini downscalate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30aafab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st=time.time()\n",
    "with h5py.File(\"resized_dataset_humerus_labelmap_res_flipped.hdf5\",\"r\") as f:\n",
    "    humerus_dataset = f.get(\"mydataset\")[:]\n",
    "print(f\"Tempo lettura dataset: {time.time()-st:.2f} sec\")\n",
    "humerus_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30b081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resized_dataset_exp = np.expand_dims(humerus_dataset,axis=-1)\n",
    "resized_dataset_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14031f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model downscaled con STRIDE (meglio)\n",
    "embedding_dim = 128\n",
    "inputs = keras.Input(shape=(resized_dataset_exp.shape[1],resized_dataset_exp.shape[2],resized_dataset_exp.shape[3],1))\n",
    "\n",
    "# Encoder\n",
    "x = Conv3D(filters=32,kernel_size=(3,3,3),padding=\"same\",name=\"conv1_1\")(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "x = Conv3D(filters=32,kernel_size=(3,3,3),strides=2,padding=\"same\",name=\"conv1_2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = Conv3D(filters=64,kernel_size=(3,4,3),padding=\"valid\",name=\"conv2_1\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "x = Conv3D(filters=64,kernel_size=(3,3,3),strides=2,padding=\"same\",name=\"conv2_2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = Conv3D(filters=128,kernel_size=(4,3,3),padding=\"valid\",name=\"conv3_1\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "x = Conv3D(filters=128,kernel_size=(3,3,3),strides=2,padding=\"same\",name=\"conv3_2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = Conv3D(filters=128,kernel_size=(3,3,3),padding=\"valid\",name=\"conv4\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "# Bottleneck\n",
    "shape_before_encoding = x.shape[1:]\n",
    "x = Flatten(name=\"flatten\")(x) \n",
    "flattened_size = x.shape[1]\n",
    "x = Dropout(0.3)(x)\n",
    "embedding = Dense(embedding_dim,activation=\"relu\",name=\"embedding\")(x)\n",
    "x = Dropout(0.3)(embedding)\n",
    "x = Dense(flattened_size,activation=\"relu\",name=\"expanding\")(x)\n",
    "x = Reshape(shape_before_encoding,name=\"reshape\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = Conv3DTranspose(filters=128,kernel_size=(3,3,3),padding=\"valid\",name=\"deconv4\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=64,kernel_size=(3,3,3),padding=\"same\",name=\"deconv3_1\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "x = Conv3DTranspose(filters=64,kernel_size=(3,3,3),strides=2,padding=\"same\",name=\"deconv3_2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=32,kernel_size=(4,3,3),padding=\"valid\",name=\"deconv2_1\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "x = Conv3DTranspose(filters=32,kernel_size=(3,3,3),strides=2,padding=\"same\",name=\"deconv2_2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=16,kernel_size=(3,4,3),padding=\"valid\",name=\"deconv1_1\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "x = Conv3DTranspose(filters=16,kernel_size=(3,3,3),strides=2,padding=\"same\",name=\"deconv1_2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = relu(x)\n",
    "\n",
    "outputs = Conv3DTranspose(filters=1,kernel_size=(3,3,3),padding=\"same\",name=\"deconv0\",activation=\"sigmoid\")(x)\n",
    "\n",
    "model_downsample = keras.Model(inputs,outputs,name=\"model_downscaled\")\n",
    "model_downsample.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0b806-eee1-4a49-b3cb-0374eaec881d",
   "metadata": {
    "tags": []
   },
   "source": [
    "with open(\"training_history/hum_loss.pkl\",\"rb\") as f1,open(\"training_history/hum_val_loss.pkl\",\"rb\") as f2,open(\"training_history/hum_dice.pkl\",\"rb\") as f3,open(\"training_history/hum_val_dice.pkl\",\"rb\") as f4:\n",
    "    tot_loss = pickle.load(f1)\n",
    "    tot_val_loss = pickle.load(f2)\n",
    "    tot_dice = pickle.load(f3)\n",
    "    tot_val_dice = pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258da0d-f3ea-47ed-af81-dc7c00e348b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tot_loss = []\n",
    "tot_val_loss = []\n",
    "tot_dice = []\n",
    "tot_val_dice = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f6c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_downsample.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[dice_coef]\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"models_weights/humerus_flipped_checkpoint.weights.h5\",\n",
    "    monitor=\"loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model_downsample.fit(\n",
    "    x=resized_dataset_exp,\n",
    "    y=resized_dataset_exp,\n",
    "    callbacks=[checkpoint],\n",
    "    # validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fd281-b2b8-4151-a948-532bc81630b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_downsample.save_weights(\"models_weights/humerus_flipped_loss0084_250ep_noval.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c68cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Non memorizzo le ultime 50 epoche senza validation \n",
    "tot_loss += history.history['loss'] # Per appendere liste tra loro\n",
    "tot_val_loss+=history.history['val_loss']\n",
    "tot_dice+=history.history['dice_coef']\n",
    "tot_val_dice+=history.history['val_dice_coef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4929a6c-bc55-4b7f-baf9-a946809a3344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"training_history/hum_flip_loss.pkl\",\"wb\") as f1,open(\"training_history/hum_flip_val_loss.pkl\",\"wb\") as f2,open(\"training_history/hum_flip_dice.pkl\",\"wb\") as f3,open(\"training_history/hum_flip_val_dice.pkl\",\"wb\") as f4:\n",
    "    pickle.dump(tot_loss,f1)\n",
    "    pickle.dump(tot_val_loss,f2)\n",
    "    pickle.dump(tot_dice,f3)\n",
    "    pickle.dump(tot_val_dice,f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a60524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"Loss\"\n",
    "fig,ax = plt.subplots(2,1,figsize=(18,18))\n",
    "start = 0\n",
    "end = 200\n",
    "\n",
    "# Loss\n",
    "ax[0].plot(tot_loss[start:end+1],marker=\".\")\n",
    "ax[0].plot(tot_val_loss[start:end+1],marker=\".\")\n",
    "ax[0].set_title('Loss del Modello')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epoche')\n",
    "ax[0].set_xticks([x for x in range(0,end+1-start,5)])\n",
    "ax[0].set_xticklabels([x for x in range(start,end+1,5)])\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "ax[0].grid()\n",
    "\n",
    "# Dice coefficient\n",
    "ax[1].plot(tot_dice[start:end+1],marker=\".\")\n",
    "ax[1].plot(tot_val_dice[start:end+1],marker=\".\")\n",
    "ax[1].set_title('Dice Coefficient del Modello')\n",
    "ax[1].set_ylabel('Dice Coefficient')\n",
    "ax[1].set_xlabel('Epoche')\n",
    "ax[1].set_xticks([x for x in range(0,end+1-start,5)])\n",
    "ax[1].set_xticklabels([x for x in range(start,end+1,5)])\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f28ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76099b7-d250-43eb-95d1-8b39fc339a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_downsample.load_weights(\"models_weights/humerus_flipped_loss0138_50ep.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd69970d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_ct = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ad64a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model_downsample(np.expand_dims(resized_dataset_exp[pred_ct],axis=0))\n",
    "pred_squeezed = np.squeeze(pred)\n",
    "pred_squeezed_binary = np.where(pred_squeezed >= 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3055f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dice_coef(np.float32(resized_dataset_exp[pred_ct]),pred_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c318e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_slice = 60\n",
    "plot_slices(resized_dataset_exp[pred_ct],2,8,start_slice,title=\"Originale\",titlesize=40)\n",
    "plot_slices(pred_squeezed_binary,2,8,start_slice,title=\"Predizione Binaria\",titlesize=40)\n",
    "plot_slices(pred_squeezed,2,8,start_slice,title=\"Predizione\",titlesize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a4a8f-d5ef-49b4-b7ed-2e75d44eade4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carico i pesi 50 epoche\n",
    "model_downsample.load_weights(\"models_weights/humerus_loss0106_100ep.weights.h5\")\n",
    "pred1 = model_downsample(np.expand_dims(resized_dataset_exp[pred_ct],axis=0))\n",
    "pred1_squeezed = np.squeeze(pred1)\n",
    "pred1_squeezed_binary = np.where(pred1_squeezed >= 0.5,1,0)\n",
    "print(dice_coef(np.float32(resized_dataset_exp[pred_ct]),pred1_squeezed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59abbb0-1756-4e8f-b13f-b35f3210dbf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carico i pesi 150 epoche\n",
    "model_downsample.load_weights(\"models_weights/humerus_loss0092_150ep.weights.h5\")\n",
    "pred2 = model_downsample(np.expand_dims(resized_dataset_exp[pred_ct],axis=0))\n",
    "pred2_squeezed = np.squeeze(pred2)\n",
    "pred2_squeezed_binary = np.where(pred2_squeezed >= 0.5,1,0)\n",
    "print(dice_coef(np.float32(resized_dataset_exp[pred_ct]),pred2_squeezed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec4fd6-c857-410c-b655-70e7f0ff3db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carico i pesi 200 epoche\n",
    "model_downsample.load_weights(\"models_weights/humerus_loss0085_200ep.weights.h5\")\n",
    "pred3 = model_downsample(np.expand_dims(resized_dataset_exp[pred_ct],axis=0))\n",
    "pred3_squeezed = np.squeeze(pred3)\n",
    "pred3_squeezed_binary = np.where(pred3_squeezed >= 0.5,1,0)\n",
    "print(dice_coef(np.float32(resized_dataset_exp[pred_ct]),pred3_squeezed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c44a99-e736-42f6-8082-a612665310d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_slice = 60\n",
    "plot_slices(resized_dataset_exp[pred_ct],1,8,start_slice,title=\"Originale\",titlesize=40)\n",
    "plot_slices(pred1_squeezed_binary,1,8,start_slice,title=\"Predizione dopo 100 epoche\",titlesize=40)\n",
    "plot_slices(pred2_squeezed_binary,1,8,start_slice,title=\"Predizione dopo 150 epoche\",titlesize=40)\n",
    "plot_slices(pred3_squeezed_binary,1,8,start_slice,title=\"Predizione dopo 200 epoche\",titlesize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a453fd9",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee3570-5563-43c9-9f38-7f22e59c45a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_downsample.load_weights(\"models_weights/humerus_checkpoint.weights.h5\") # Il checkpoint contiene quello con loss minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c6590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_model = keras.Model(model_downsample.inputs,model_downsample.get_layer(\"embedding\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86543807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = feature_model.predict(resized_dataset_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6ba11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbdfc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"processing/humerus_res_flip_features_250ep.pkl\",\"wb\") as f:\n",
    "    pickle.dump(features,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1aa58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization (da qui su altro file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() # Prova anche con tutte le dimensioni\n",
    "pca.fit(features)\n",
    "cumulative_sum = pca.explained_variance_ratio_.cumsum() # Per vedere quanta varianza catturo e scegliere il numero di PC\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(cumulative_sum,marker=\"o\")\n",
    "ax.set_title(\"Cumulative sum of variance ratio\")\n",
    "ax.set_xlim(0,10)\n",
    "print(cumulative_sum[:10])\n",
    "# Catturo già il 94% della varianza con 4 PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 4\n",
    "st = time.time()\n",
    "features_pca = PCA(n_components=num_components).fit_transform(features) # Userò anche per il clustering\n",
    "features_tsne = TSNE(n_iter=1000,verbose=1).fit_transform(features_pca) # Per la visualizzazione in 2D\n",
    "print(f\"Tempo dimensionality reduction: {time.time()-st:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "print(features_pca.shape)\n",
    "print(features_tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scatter={}\n",
    "data_scatter[\"dim1\"] = features_tsne[:,0]\n",
    "data_scatter[\"dim2\"] = features_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc = {'figure.figsize':(20, 15)})\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    data = data_scatter,\n",
    "    x = \"dim1\",\n",
    "    y = \"dim2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cb319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8bf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampo l'inerzia (distanza within cluster) per vari numeri di cluster per vedere qual è il numero di cluster ottimale (gomito)\n",
    "distortions = []\n",
    "sil = []\n",
    "dbs = []\n",
    "chi = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    kmeanModel = KMeans(n_clusters=k,n_init=\"auto\")\n",
    "    # kmeanModel.fit(features_pca)\n",
    "    labels = kmeanModel.fit_predict(features_pca)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "    if k > 1:\n",
    "        sil.append(silhouette_score(features_pca,labels))\n",
    "        dbs.append(davies_bouldin_score(features_pca,labels)) \n",
    "        chi.append(calinski_harabasz_score(features_pca,labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "sns.lineplot(x=range(2,10),y=sil,ax=ax[0],marker=\"o\")\n",
    "ax[0].set_title(\"Silhouette\")  # Da -1 a 1, meglio 1, distanze intra e inter cluster medie\n",
    "sns.lineplot(x=range(2,10),y=dbs,ax=ax[1],marker=\"o\")\n",
    "ax[1].set_title(\"Davies-Bouldin\") # Più basso è meglio è, distanza intra cluster bassa e inter alta porta ad un indice basso\n",
    "sns.lineplot(x=range(2,10),y=chi,ax=ax[2],marker=\"o\")\n",
    "ax[2].set_title(\"Calinski and Harabasz\") \n",
    "# Più alto è meglio è, basato su distanze dei punti dentro un cluster dal centroide e distanze dei centroidi dei cluster\n",
    "# dal centroide globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e086074",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(1,10),y=distortions,marker=\"o\")\n",
    "plt.title(\"Inertia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e8fcb",
   "metadata": {},
   "source": [
    "Tutto sembra indicare che il numero ideale di cluster sia 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il gomito è intorno a 3-4-5 cluster\n",
    "number_clusters = 3\n",
    "kmeans = KMeans(n_clusters=number_clusters,n_init=\"auto\")\n",
    "labels = kmeans.fit_predict(features_pca) # KMeans non su 150 features per curse of dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbscan = DBSCAN(eps=3,min_samples=5)\n",
    "#labels = dbscan.fit_predict(features_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scatter[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    data = data_scatter,\n",
    "    x = \"dim1\",\n",
    "    y = \"dim2\",\n",
    "    hue= \"labels\",\n",
    "    palette=sns.color_palette(\"bright\",number_clusters)\n",
    ")\n",
    "# Visualizzare con visualizzatore apposta cliccabile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48d18a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Heatmap\n",
    "\n",
    "Coregistrazione CT mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708af6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provo ad ottenre una heatmap dell'ultimo livello dell'encoder per vedere dove si concentra l'estrazione delle feature\n",
    "\n",
    "image_n = 110\n",
    "conv_layer = model_downsample.get_layer(\"conv4\")\n",
    "heatmap_model = keras.Model(inputs=model_downsample.input, outputs=[conv_layer.output,model_downsample.output])\n",
    "in_img = tf.Variable(np.expand_dims(resized_dataset_exp[image_n],axis=0),dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as gtape:\n",
    "    gtape.watch(in_img)\n",
    "    heatmap_output, prediction = heatmap_model(in_img) # È come predict, ma da usare quando voglio differenziarlo (come qui)\n",
    "    \n",
    "grads = gtape.gradient(prediction,heatmap_output)\n",
    "chan_importance = tf.reduce_mean(grads,axis=(0,1,2,3)) # Calcolo un valore che indica l'importanza di ogni canale\n",
    "\n",
    "heatmap = tf.reduce_mean(heatmap_output*chan_importance,axis=-1)\n",
    "print(np.min(heatmap),np.max(heatmap))\n",
    "\n",
    "# Per normalizzare riduco il minimo a 0 e normalizzo tra 0 e 1\n",
    "heatmap = tf.maximum(abs(heatmap),0) # Son tutti negativi, metto abs\n",
    "print(np.min(heatmap),np.max(heatmap))\n",
    "\n",
    "heatmap /= tf.reduce_max(heatmap)  # Normalizzo la heatmap tra 0 e 1\n",
    "print(np.min(heatmap),np.max(heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_output.shape,prediction.shape,grads.shape,chan_importance.shape,heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_slices_notzero(np.squeeze(heatmap_output)[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abaef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1264b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.squeeze(np.asarray(heatmap))\n",
    "heatmap_res = resize(heatmap,output_shape=(in_img.shape[1],in_img.shape[2],in_img.shape[3]))\n",
    "plot_all_slices_notzero(heatmap_res)\n",
    "# heat_opencv = cv2.resize(heatmap,(in_img.shape[1],in_img.shape[2],in_img.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_slice = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_res.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "superimposed_images = []\n",
    "for ct_slice in range(heatmap_res.shape[2]): # Le slice\n",
    "    heat_img = np.uint8(heatmap_res[:,:,ct_slice]*255) # Moltiplico per 255 per visualizzazione\n",
    "    in_img_cv = np.uint8(np.where(np.squeeze(in_img)[:,:,ct_slice] == 0,255,0)) # Cambio colori foreground e background per visualizzare meglio la heatmap \n",
    "    heat_img = cv2.applyColorMap(heat_img, cv2.COLORMAP_JET)\n",
    "    in_img_cv = cv2.applyColorMap(in_img_cv, cv2.COLORMAP_BONE)\n",
    "    superimposed_img = heat_img*0.9 + in_img_cv*0.7\n",
    "    #plt.imshow(np.clip(superimposed_img,0,255).astype(\"uint8\"))\n",
    "    superimposed_images.append(np.clip(superimposed_img,0,255).astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "superimposed_images = np.asarray(superimposed_images,dtype=np.uint8)\n",
    "nrows = 16\n",
    "ncols = 8\n",
    "fig,ax = plt.subplots(\n",
    "    nrows,\n",
    "    ncols,\n",
    "    figsize = (40,int(40/ncols)*nrows),\n",
    "    constrained_layout=True\n",
    ")\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        index = i*ncols+j\n",
    "        ax[i,j].imshow(superimposed_images[index])\n",
    "        ax[i,j].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device(\"/GPU:0\"):\n",
    "inputs = keras.Input(shape=(humerus_dataset.shape[1],humerus_dataset.shape[2],humerus_dataset.shape[3],1))\n",
    "\n",
    "# Encoder\n",
    "x = Conv3D(filters=16,kernel_size=(4,4,3),activation=\"relu\",padding=\"valid\",name=\"conv1\")(inputs)\n",
    "x = MaxPooling3D(pool_size=(2,2,2),name=\"pool1\")(x)\n",
    "\n",
    "x = Conv3D(filters=32,kernel_size=(3,4,3),activation=\"relu\",padding=\"valid\",name=\"conv2\")(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2),name=\"pool2\")(x)\n",
    "\n",
    "x = Conv3D(filters=64,kernel_size=(3,3,4),activation=\"relu\",padding=\"valid\",name=\"conv3\")(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2),name=\"pool3\")(x)\n",
    "\n",
    "x = Conv3D(filters=128,kernel_size=(3,4,3),activation=\"relu\",padding=\"valid\",name=\"conv4\")(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2),name=\"pool4\")(x)\n",
    "\n",
    "shape_before_encoding = x.shape[1:]\n",
    "print(shape_before_encoding)\n",
    "# Feature extraction\n",
    "x = Flatten(name=\"flatten\")(x) \n",
    "flattened_size = x.shape[1]\n",
    "print(flattened_size)\n",
    "embedding = Dense(100,activation=\"relu\",name=\"embedding\")(x)\n",
    "x = Dense(flattened_size,activation=\"relu\",name=\"expanding\")(embedding)\n",
    "x = Reshape(shape_before_encoding,name=\"reshape\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = Conv3DTranspose(filters=64,kernel_size=(3,3,4),activation=\"relu\",padding=\"same\",name=\"deconv4\")(x)\n",
    "x = UpSampling3D((2,2,2),name=\"upsample4\")(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=64,kernel_size=(3,4,3),activation=\"relu\",padding=\"valid\",name=\"deconv3\")(x)\n",
    "x = UpSampling3D((2,2,2),name=\"upsample3\")(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=32,kernel_size=(3,3,4),activation=\"relu\",padding=\"valid\",name=\"deconv2\")(x)\n",
    "x = UpSampling3D((2,2,2),name=\"upsample2\")(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=16,kernel_size=(3,4,3),padding=\"valid\",name=\"deconv1\")(x)\n",
    "x = UpSampling3D((2,2,2),name=\"upsample1\")(x)\n",
    "\n",
    "outputs = Conv3DTranspose(filters=1,kernel_size=(4,4,3),padding=\"valid\",name=\"deconv0\",activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs,outputs,name=\"model_1_200\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b685286",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.Accuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f53c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_1_200.shape)\n",
    "in_shape = (humerus_dataset.shape[1],humerus_dataset.shape[2],humerus_dataset.shape[3],1)\n",
    "dataset_1_200_expanded = np.expand_dims(humerus_dataset[:100],axis=-1) # solo i primi 100\n",
    "dataset_1_200_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aebce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device(\"/GPU:0\"):\n",
    "model.fit(\n",
    "    x=dataset_1_200_expanded,\n",
    "    y=dataset_1_200_expanded,\n",
    "    batch_size=2,\n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30085b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ct = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_downsample.predict(np.expand_dims(resized_dataset_exp[pred_ct],axis=0))\n",
    "pred_squeezed = np.squeeze(pred)\n",
    "pred_squeezed_binary = np.where(pred_squeezed >= 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0586416",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_slice = 55\n",
    "plot_slices(resized_dataset_exp[pred_ct],3,8,start_slice)\n",
    "plot_slices(pred_squeezed_binary,3,8,start_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_slices_notzero(resized_dataset_exp[pred_ct])\n",
    "plot_all_slices_notzero(pred_squeezed_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17038652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
